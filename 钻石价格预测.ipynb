{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查pycaret的版本，确保可以运行。\n",
    "- 需要2.0.0及以上\n",
    "\n",
    "注意2.2.0版本如果用 pip install pycaret安装，catboost、xgboost缺省是不装的。\n",
    "本例中，安装了全集 pip install pycaret[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:49:10.077006Z",
     "start_time": "2020-10-14T11:49:08.487209Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pycaret\n",
    "pycaret.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课程内容：\n",
    "\n",
    "- 导入数据：从PyCaret的datasets中导入数据\n",
    "- 设置环境：在PyCaret中设置实验并开始构建回归模型\n",
    "- 创建模型：执行交叉验证和评估回归指标\n",
    "- 调整模型：自动调整回归模型的超参数（需要人为设定的参数叫做超参数）\n",
    "- 结果绘图：使用各种绘图，分析模型性能\n",
    "- 预测模型：对测试集进行预测\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据\n",
    "使用数据集：\"Sarah Gets a Diamond\"。数据来源于一个浪漫MBA学生(真的，没开玩笑)为自己的新娘莎拉选择合适的钻石的案例。\n",
    "\n",
    "数据包含6000条记录。每列的简短描述如下：\n",
    "\n",
    "    ID：每颗钻石的独一无二的编号\n",
    "    Carat Weight：重量，公制克拉中钻石的重量。\n",
    "    Cut：切割工艺，五个值之一(Signature-Ideal, Ideal, Very Good, Good, Fair)\n",
    "    Color：颜色，六个值之一(D, E, F - Colorless, G, H, I - Near colorless)\n",
    "    Clarity：净度，七个值之一(F - Flawless, IF - Internally Flawless, VVS1 or VVS2 - Very, Very Slightly Included, or VS1 or VS2 - Very Slightly Included, SI1 - Slightly Included)\n",
    "    Polish：抛光度，四个值之一(ID - Ideal, EX - Excellent, VG - Very Good, G - Good)\n",
    "    Symmetry：对称性，四个值之一(ID - Ideal, EX - Excellent, VG - Very Good, G - Good)\n",
    "    Report：评估钻石质量的分级机构，两个值之一(\"AGSL\", \"GIA\")\n",
    "    Price：钻石价格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "利用get_data()函数下载数据集（需要联网）\n",
    "\n",
    "然后，我们复习一下上节课的内容：对数据处理的异常值检测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:49:11.340582Z",
     "start_time": "2020-10-14T11:49:10.079864Z"
    }
   },
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "# import pandas as pd\n",
    "dataset = get_data('diamond')\n",
    "\n",
    "# file_name='./diamond.csv'\n",
    "# dataset=pd.read_csv(file_name)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:49:11.350391Z",
     "start_time": "2020-10-14T11:49:11.346581Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型对于文字信息的处理能力没有对数字信息强，所以，对数据的文字部分(具体说Cut,Color,Clarity,Polish,Symmetry,Report六列)，我们选择将其转化为对应数字。同时，数字信息也便于绘图和进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:49:11.381431Z",
     "start_time": "2020-10-14T11:49:11.352134Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in dataset.columns:\n",
    "    if i not in ['Carat Weight', 'Price']:\n",
    "        dataset[i].replace(dataset[i].unique().tolist(), \n",
    "                           np.arange(len(dataset[i].unique().tolist())), \n",
    "                           inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与上面的dataset对比，观察到，文字内容已经变成数字了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:49:11.393254Z",
     "start_time": "2020-10-14T11:49:11.383570Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后使用杀手锏pandas_profiling一步看清数据的大致特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:49:23.863602Z",
     "start_time": "2020-10-14T11:49:11.395521Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "pfr = pandas_profiling.ProfileReport(dataset)\n",
    "pfr.to_file('report.html')\n",
    "pfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便使用pycaret进行机器学习，我们选择的数据集非常干净，不存在异常值。但是同学们需要注意，真实情况下，数据集往往是不干净的，面对一份全新的数据，清洗工作不可或缺，而常用的清洗方法我们上节课介绍过，当一份数据集被清洗完成后，我们就可以开始机器学习的旅程啦！\n",
    "\n",
    "还是复习上节课的内容，我们绘制不同特征的两两散点图，来肉眼观察一下数据间的关联性，同时寻找数据是否存在异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:49:41.185346Z",
     "start_time": "2020-10-14T11:49:23.868631Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(context='talk', style='ticks', font_scale=0.98)\n",
    "sns.pairplot(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于数据的离散类型较大，所以绘制的图像看着非常工整，原因也很简单，当横纵坐标都是离散值时，绘制的图像只可能在几个特定位置出现数据点。所以这样的数据其实并不能得到很多信息。\n",
    "\n",
    "- 不过，从图中还是可以得到一些信息的。\n",
    "- 观察左下角的price-carat weight散点图，明显看到了数据存在正相关关系，说明钻石的价格与克拉重量有正相关关系。\n",
    "- 观察左上角的carat weight分布图，发现钻石的重量是存在两个峰值的，就是说钻石存在小钻石类和大钻石类，也比较符合我们的认知：碎钻，整钻。\n",
    "- 观察右下角的price分布图，发现钻石的分布区间明显在低价格部分，说明贵的钻石虽然有人买，但是大部分人还是穷人啊。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集划分\n",
    "为了对未知数据进行预测，从原始数据集中保留了600条记录的样本。将总共6000条数据拆分为5400+600条。\n",
    "\n",
    "- 模拟现实生活场景，总有些情况是没有遇到过的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:49:41.197568Z",
     "start_time": "2020-10-14T11:49:41.187787Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dataset.sample(frac=0.9, random_state=786)\n",
    "data_unseen = dataset.drop(data.index)\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data_unseen.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('Data for Modeling: ' + str(data.shape))\n",
    "print('Unseen Data For Predictions: ' + str(data_unseen.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置环境\n",
    "使用setup()函数初始化pycaret中的环境。\n",
    "\n",
    "在pycaret中执行任何其他功能之前，必须先调用setup()。\n",
    "它具有两个必填参数：\n",
    "\n",
    "    data：填入一个dataframe\n",
    "    teraget：填入列名\n",
    "\n",
    "当执行setup()时，PyCaret的推断算法将根据某些属性自动推断所有功能的数据类型,自动判断通常存在错误的可能。为了解决这个问题，在执行setup()之后，PyCaret将显示一个包含特征及其推断的数据类型的表。\n",
    "\n",
    "    推断正确：Enter键\n",
    "    推断错误：quit键\n",
    "\n",
    "pycaret会自动执行一些预处理任务，对于不同数据类型，处理方式往往不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:49:46.950280Z",
     "start_time": "2020-10-14T11:49:41.201144Z"
    }
   },
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "exp_reg101 = setup(data = data, target = 'Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "成功执行set()后，会打印包含一些重要信息的信息表。为了pycaret的通用性，所以显示了大量信息，但是绝大多数信息并没有在本次任务中使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型\n",
    "\n",
    "### 评估性能\n",
    "\n",
    "在完成set()完成后比较所有模型以评估性能（对所有模型进行训练，因为无法确切判断需要使用哪种模型）\n",
    "\n",
    "此功能训练模型库中的所有模型，并使用k值交叉验证对模型进行度量评估。\n",
    "\n",
    "输出数据表显示出各种对模型的评价指标：\n",
    "- average MAE，平均绝对误差\n",
    "- MSE，均方误差\n",
    "- RMSE，均方根误差\n",
    "- R2，决定系数\n",
    "- RMSLE，均方根对数误差\n",
    "- MAPE（默认为10），平均绝对百分误差\n",
    "- training time，训练时间\n",
    "\n",
    "这些指标背后都存在着数学意义，每个指标都反映了模型的性能。可以参考[知乎评价指标解释](https://zhuanlan.zhihu.com/p/86120987?from_voters_page=true) \n",
    "\n",
    "这里有一个小技巧，除了R2以外的所有指标，数值越小表示模型效果越好,R2(小于1)则是数值越大越好。pycaret默认的是R2为评价模型的首要指标，我们也这样做，对模型评价，R2值接近1，意味着模型效果越好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:50:59.123934Z",
     "start_time": "2020-10-14T11:49:46.952846Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一行代码，训练和评估了19个模型！！！\n",
    "\n",
    "数据表高亮了性能最高的模型。默认情况下，表格使用R2（从最高到最低）进行排序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择模型训练\n",
    "model()函数显示了pycaret可以使用的回归模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:50:59.138800Z",
     "start_time": "2020-10-14T11:50:59.125894Z"
    }
   },
   "outputs": [],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据模型评估的性能，以及模型的通用程度，我们选择以下三种模型进行进一步训练：\n",
    "\n",
    "- CatBoost Regressor(效果最好，但是计算慢)\n",
    "- Linear Regression(最基础)\n",
    "- Random Forest（使用普遍）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:51:15.982893Z",
     "start_time": "2020-10-14T11:50:59.141064Z"
    }
   },
   "outputs": [],
   "source": [
    "ada = create_model('ada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:51:15.987634Z",
     "start_time": "2020-10-14T11:51:15.984677Z"
    }
   },
   "outputs": [],
   "source": [
    "print(ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:51:16.309937Z",
     "start_time": "2020-10-14T11:51:15.989700Z"
    }
   },
   "outputs": [],
   "source": [
    "lightgbm = create_model('lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:51:16.315050Z",
     "start_time": "2020-10-14T11:51:16.312059Z"
    }
   },
   "outputs": [],
   "source": [
    "print(lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:51:19.398727Z",
     "start_time": "2020-10-14T11:51:16.317546Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = create_model('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:51:19.404404Z",
     "start_time": "2020-10-14T11:51:19.400493Z"
    }
   },
   "outputs": [],
   "source": [
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，所有模型的平均分数与 compare_models() 中打印的分数相匹配。 这是因为在 compare_models() 分数网格中打印的指标是所有 CV 折叠的平均分数。 与 compare_models() 类似，如果要将 fold 参数从默认值 10 更改为不同的值，则可以使用 fold 参数。 例如： create_model('dt', fold = 5) 使用 5 折交叉验证创建决策树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整模型\n",
    "\n",
    "使用create_model函数创建模型时，是使用默认的超参数来训练模型的。在选定了使用模型后，为了提高精度，我们需要调整超参数，pycaret提供了tune_model函数，一键调整超参数。\n",
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:52:16.202569Z",
     "start_time": "2020-10-14T11:51:19.406396Z"
    }
   },
   "outputs": [],
   "source": [
    "tuned_ada = tune_model(ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lgbm_params = {'num_leaves': np.arange(10,200,10),\n",
    "            'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "            'learning_rate': np.arange(0.1,1,0.1)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_lightgbm = tune_model(lightgbm, custom_grid = lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuned_lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_dt = tune_model(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果绘图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模型训练完成后，使用plot_model()函数分析不同方面的性能，例如残差图，预测误差图，特征重要性图等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 残差图\n",
    "残差在数理统计中是指真实值与预测值之间的差。\n",
    "\n",
    "残差图是指以某种残差为纵坐标，以其他适宜的量为横坐标的散点图。\n",
    "该残差图的横坐标为预测值，纵坐标为残差，看出残差并没有随着预测范围的改变而出现极大变化，比较均匀地分布在预测价格的横坐标上。这反映了模型在预测上并没有”偏科“，对所有价格的钻石都有比较合理的预测结果。\n",
    "- 特别需要注意的是，蓝色点为训练集，绿色点为测试集，图中明显看出，蓝色点的残差更加小，这是机器学习结果的常态，即训练集效果优于测试集效果。\n",
    "- 有兴趣的同学可以思考一下为什么会这样？\n",
    "- 会不会存在测试集效果和训练集效果一样好的情况？\n",
    "- 是不是训练的残差越小越好。\n",
    "\n",
    "这些问题的思考有助于同学们加深对机器学习的理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:52:17.125504Z",
     "start_time": "2020-10-14T11:52:16.204954Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(tuned_lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_lightgbm, plot = 'error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测重要性图\n",
    "\n",
    "展示了数据不同特征对预测结果的重要性。由图显示，钻石的克拉重量对钻石价格的重要性最大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:52:17.345026Z",
     "start_time": "2020-10-14T11:52:17.127569Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(tuned_lightgbm, plot='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测模型\n",
    "\n",
    "还记得最初留下的600个数据嘛？predict_model()函数将模型在看不见的数据集上进行预测。 \n",
    "\n",
    "我们将传递data_unseen参数。data_unseen是在任务开始时创建的变量，包含从未暴露给PyCaret的原始数据集的10％（600个样本）。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:52:17.457452Z",
     "start_time": "2020-10-14T11:52:17.347526Z"
    }
   },
   "outputs": [],
   "source": [
    "unseen_predictions = predict_model(tuned_lightgbm, data=data_unseen)\n",
    "unseen_predictions.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label列添加到data_unseen表的最后一列，label列是使用Random Forest模型对特征进行预测结果，可以发现label列数值与price列数值是非常接近的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T12:57:24.525817Z",
     "start_time": "2020-10-13T12:58:28.370Z"
    }
   },
   "source": [
    "计算预测值与真实值的R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T11:52:17.471660Z",
     "start_time": "2020-10-14T11:52:17.465427Z"
    }
   },
   "outputs": [],
   "source": [
    "from pycaret.utils import check_metric\n",
    "check_metric(unseen_predictions.Price, unseen_predictions.Label, 'R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
