{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用pycaret.nlp模块进行自然语言处理。\n",
    "\n",
    "学习内容：\n",
    "\n",
    "    设置环境：在PyCaret中设置环境并执行关键的文本预处理任务。\n",
    "    创建模型：创建topic model。\n",
    "    分配模型：使用经过训练的模型将文档/文本分配给主题。\n",
    "    绘制图表：使用图表分析topic model/语料库。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据集处理\n",
    "数据集包含6818个样本。特征的描述如下：\n",
    "\n",
    "    country\t：借款国\n",
    "    en：申请贷款时借款人的个人经历\n",
    "    gender：性别（M =男性，F =女性）\n",
    "    loan_amount：已批准和已支付的贷款金额\n",
    "    nonpayment：贷方类型（lender\t：Kiva网站上的个人注册用户，partner：与Kiva合作寻找并资助贷款的小额信贷机构）\n",
    "    sector：借款人行业\n",
    "    status：贷款状态（1：未还款，0：还款）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.310Z"
    }
   },
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv('./NLP/LDA_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集共有6818条，若电脑无法运行这么大的话，取其中1000条运行。（后续绘图会比较卡）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.312Z"
    }
   },
   "outputs": [],
   "source": [
    "#check the shape of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卡就运行，不卡就别运行了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.313Z"
    }
   },
   "outputs": [],
   "source": [
    "# sampling the data to select only 1000 documents\n",
    "data = data.sample(1000, random_state=786).reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 设置环境\n",
    "setup()函数会初始化pycaret中的环境，并执行一些必须处理NLP问题的文本预处理步骤。在pycaret中执行任何其他功能之前，必须先调用setup()函数。\n",
    "\n",
    "执行设置后，将自动应用以下预处理步骤：\n",
    "\n",
    "    - 删除数字字符：从文本中删除所有数字字符。\n",
    "    - 删除特殊字符：从文本中删除所有非字母数字的特殊字符。\n",
    "    - Word Tokenization：单词标记化是将大量文本样本拆分为多个单词的过程。\n",
    "    - 停用词的删除：很常见，即使对于语言有意义，它也对信息检索几乎没有价值。“the”，“a”，“an”，“in”\n",
    "    还有很多。。。。。。\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T14:24:38.847542Z",
     "start_time": "2020-10-26T14:24:38.843848Z"
    }
   },
   "source": [
    "安装需要的语言模型\n",
    "python命令行界面，例如Anaconda Prompt，在命令行中输入以下内容：\n",
    "- python -m spacy download en_core_web_sm\n",
    "- python -m textblob.download_corpora\n",
    "\n",
    "然后运行下面的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.314Z"
    }
   },
   "outputs": [],
   "source": [
    "from pycaret.nlp import *\n",
    "exp_nlp101 = setup(data = data, target = 'en', session_id = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当执行setup()时，所有文本预处理步骤都会自动执行,这些步骤对于在NLP中都是必不可少的。这里极大地简化了这个过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.创建模型\n",
    "在PyCaret中创建topic model非常简单，使用create_model()函数创建topic model.该函数采用一个强制性参数，即模型名称作为字符串。此函数返回一个训练好的模型对象。\n",
    "\n",
    "PyCaret中有5种topic model。这里我们使用LDA模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.317Z"
    }
   },
   "outputs": [],
   "source": [
    "lda = create_model('lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.318Z"
    }
   },
   "outputs": [],
   "source": [
    "print(lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 分配模型\n",
    "现在我们已经创建了一个topic model，我们将给数据集（6818个文档/样本）倒入模型加以分析结果。 我们将使用assign_model()函数来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.320Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_results = assign_model(lda)\n",
    "lda_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在dataframe里增加了6个列。Topic_0 ... Topic_3是主题比例（默认分为4类，可以修改），代表每个文档的主题分布。Dominant_Topic是具有最高比例的topic编号，而Perc_Dominant_Topic是占主导topic的比例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 绘制图表\n",
    "plot_model()函数可用于分析整个语料库或仅分析通过主题模型提取的特定主题。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整个语料库的单词频率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.322Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Topic 1的频率分布\n",
    "plot_model()也可以用于分析特定topic。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.324Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(lda, plot = 'frequency', topic_num = 'Topic 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic的分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.325Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(lda, plot = 'topic_distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE\n",
    "T分布随机邻居嵌入（t-SNE）是一种非线性降维技术，非常适合在二维或三维低维空间中嵌入高维数据以进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-26T15:34:35.327Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(lda, plot = 'tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
